{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "cccb7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "280c9324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert(imgs, labels, outfile, n):\n",
    "#     imgf = open(imgs, \"rb\")\n",
    "#     labelf = open(labels,\"rb\")\n",
    "#     csvf = open(outfile, \"w\")\n",
    "    \n",
    "#     imgf.read(16)\n",
    "#     labelf.read(8)\n",
    "#     images = []\n",
    "    \n",
    "#     for i in range(n):\n",
    "#         image = [ord(labelf.read(1))]\n",
    "#         for j in range(28*28):\n",
    "#             image.append(ord(imgf.read(1)))\n",
    "#         images.append(image)\n",
    "        \n",
    "#     for image in images:\n",
    "#         csvf.write(\",\".join(str(pix) for pix in image) + \"\\n\")\n",
    "#     imgf.close()\n",
    "#     labelf.close()\n",
    "#     csvf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2ce296e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_train_x = r\"C:\\Users\\Hp\\Downloads\\train-images.idx3-ubyte\"\n",
    "# mnist_train_y = r\"C:\\Users\\Hp\\Downloads\\train-labels.idx1-ubyte\"\n",
    "# mnist_test_x =  r\"C:\\Users\\Hp\\Downloads\\t10k-images.idx3-ubyte\"\n",
    "# mnist_test_y = r\"C:\\Users\\Hp\\Downloads\\t10k-labels.idx1-ubyte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "39af3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert(mnist_train_x, mnist_train_y, r\"C:\\Users\\Hp\\Downloads\\train.csv\", 60000)\n",
    "# convert(mnist_test_x, mnist_test_y,r\"C:\\Users\\Hp\\Downloads\\test.csv\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9de5a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt(\"train.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "efe7850d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "afabb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=train[:,784:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7659002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=train[:,:784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4e049bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "cf22e517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e1bf4d7730>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train1[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "395921f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN:\n",
    "\n",
    "    def __init__ (self,input_layer_size,hidden_layer_size,num_labels,X, y ):\n",
    "        self.input_layer_size = input_layer_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.num_labels=num_labels\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "      \n",
    "        \n",
    "    def sigmoid(self,z):\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def sigmoidGradient(self,z):\n",
    "        g = np.zeros(z.shape)\n",
    "        g = sigmoid(z) * (1 - sigmoid(z))\n",
    "        return g\n",
    "\n",
    "    def ReLU(self, Z, derivative = False):\n",
    "        if derivative:\n",
    "            return Z>0\n",
    "        return np.maximum(0,Z)\n",
    "\n",
    "    def softmax(self, x, derivative=False):\n",
    "        exps = np.exp(x-x.max())\n",
    "        if derivative:\n",
    "            return exps/np.sum(exps,axis=0)*(1-exps/np.sum(exps,axis=0))\n",
    "        return exps/np.sum(exps,axis=0)\n",
    "    \n",
    "    def predict(self,Theta1, Theta2, X):\n",
    "        # Useful values\n",
    "        m = X.shape[0]\n",
    "        num_labels = Theta2.shape[0]\n",
    "        # You need to return the following variables correctly\n",
    "        p = np.zeros(m)\n",
    "        h1 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), X], axis=1), Theta1.T))\n",
    "        h2 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), h1], axis=1), Theta2.T))\n",
    "        p = np.argmax(h2, axis=1)\n",
    "        return p\n",
    "    \n",
    "    def randInitializeWeights(self,L_in, L_out, epsilon_init=0.12):\n",
    "        W = np.zeros((L_out, 1 + L_in))\n",
    "        W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "        return W  \n",
    "    \n",
    "    def weight(self):\n",
    "        initial_Theta1 = randInitializeWeights(self.input_layer_size, hidden_layer_size)\n",
    "        initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
    "\n",
    "        # Unroll parameters\n",
    "        initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel()], axis=0)\n",
    "        return initial_nn_params\n",
    "    \n",
    "    def Back_propogation(self,nn_params,input_layer_size,hidden_layer_size,num_labels,X, y,lambda_):\n",
    "        \n",
    "\n",
    "    \n",
    "        Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, (input_layer_size + 1))) # 25 x 401\n",
    "\n",
    "        Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size + 1))) \n",
    "        m = y.size\n",
    "        a1 = np.concatenate([np.ones((m, 1)), X], axis=1) \n",
    "    \n",
    "        z2 = np.dot(a1, Theta1.T)\n",
    "        a2 = sigmoid(z2)\n",
    "\n",
    "        a2 = np.concatenate([np.ones((m, 1)), a2], axis=1) \n",
    "        \n",
    "        z3 = np.dot(a2, Theta2.T) \n",
    "        a3 = sigmoid(z3)  \n",
    "        \n",
    "        y_matrix = y.reshape(-1)\n",
    "#         print(y_matrix)\n",
    "#         print(num_labels)\n",
    "        y_matrix = np.eye(num_labels)[y_matrix.astype(int)]\n",
    "            \n",
    "\n",
    "        J = (-1/m) * (np.sum(y_matrix * np.log(a3) + (1-y_matrix) * np.log(1-a3)))\n",
    "    \n",
    "    \n",
    "        Reg = (lambda_/(2*m)) * (np.sum(np.square(Theta1[:, 1:])) + np.sum(np.square(Theta2[:, 1:])))\n",
    "        J = J + Reg\n",
    "    \n",
    "        # Part 2: Backpropagation\n",
    "\n",
    "        # Implementing the vectorized approach\n",
    "        # Step 1\n",
    "        # Comes from the forward propagation process(Part 1)\n",
    "    \n",
    "        # Step 2\n",
    "        d3 = a3 - y_matrix  # 5000 x 10\n",
    "        \n",
    "\n",
    "        d2 = np.dot(d3, Theta2[:, 1:]) * sigmoidGradient(z2)  # 5000 x 25\n",
    "  \n",
    "        Delta1 = np.dot(d2.T, a1)  # 25 x 401\n",
    "        Delta2 = np.dot(d3.T, a2)  # 10 x 26\n",
    "        \n",
    "        # Step 5\n",
    "        Theta2_grad = (1/m) * Delta2\n",
    "        Theta1_grad = (1/m) * Delta1\n",
    "    \n",
    " \n",
    "        Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (lambda_/m) * Theta2[:, 1:]\n",
    "        Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (lambda_/m) * Theta1[:, 1:]\n",
    "        \n",
    "        # ================================================================\n",
    "        # Unroll gradients\n",
    "        # grad = np.concatenate([Theta1_grad.ravel(order=order), Theta2_grad.ravel(order=order)])\n",
    "        grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n",
    "\n",
    "        return J, grad\n",
    "    \n",
    "    def train(self,X,y):\n",
    "        \n",
    "        from scipy import optimize\n",
    "        options= {'maxiter': 2}\n",
    "        initial_nn_params=self.weight()\n",
    "        #  You should also try different values of lambda\n",
    "        lambda_ = 1\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        # Create \"short hand\" for the cost function to be minimized\n",
    "        costFunction = lambda p:self.Back_propogation(p, input_layer_size,\n",
    "                                        hidden_layer_size,\n",
    "                                        num_labels,X,y, lambda_)\n",
    "\n",
    "        # Now, costFunction is a function that takes in only one argument\n",
    "        # (the neural network parameters)\n",
    "        res = optimize.minimize(costFunction,\n",
    "                        initial_nn_params,\n",
    "                        jac=True,\n",
    "                        method='TNC',\n",
    "                        options=options)\n",
    "\n",
    "    # get the solution of the optimization\n",
    "        nn_params = res.x\n",
    "        \n",
    "    # Obtain Theta1 and Theta2 back from nn_params\n",
    "        Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                    (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "        Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                    (num_labels, (hidden_layer_size + 1)))\n",
    "        \n",
    "        pred = predict(Theta1, Theta2, X)\n",
    "        # print(pred)\n",
    "        print('Training Set Accuracy: %f' % (np.mean(pred == y) * 100))\n",
    "        \n",
    "        return Theta1,Theta2\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ab0c2858",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size  = 784 \n",
    "hidden_layer_size = 25 \n",
    "num_labels = 10    \n",
    "x=DNN(input_layer_size,hidden_layer_size,num_labels,train1,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d8953f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_3152\\2831633526.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "theta1,theta2=x.train(train1,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "cfe4457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.loadtxt(\"test.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ff67dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test=test[:,784:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "5f9bdd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=test[:,:784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "82459bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_3152\\2831633526.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "p=x.predict(theta1,theta2,data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8593287f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "print('Training Set Accuracy: %f' % (np.mean(p == labels_test) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
